{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import hsn_v1\n",
    "import keras\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_path = 'folds/glas/split_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_files = [str(path) for path in Path(folds_path).rglob('*.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(pattern):\n",
    "    def filter_inst(file):\n",
    "        if pattern in file:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return filter_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and sort CV csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv = list(filter(make_filter('valid'), folds_files))\n",
    "valid_csv.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = list(filter(make_filter('test'), folds_files))\n",
    "test_csv.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = list(filter(make_filter('train'), folds_files))\n",
    "train_csv.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_csv(file):\n",
    "#     cols = [0,1,2]\n",
    "#     col_names = ['img', 'gt', 'class']    \n",
    "#     df = pd.read_csv(file, header=None, usecols=cols, names=col_names)\n",
    "#     files = df[col_names[0]].tolist()\n",
    "#     names = [f.replace('.bmp', '') + '_' for f in files]\n",
    "#     return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    cols = [0,1,2]\n",
    "    col_names = ['img', 'gt', 'class']    \n",
    "    df = pd.read_csv(file, header=None, usecols=cols, names=col_names)\n",
    "    files = df[col_names[0]].tolist()\n",
    "    names = [f.replace('.bmp', '.png') for f in files]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [read_csv(file) for file in train_csv]\n",
    "test_files = [read_csv(file) for file in test_csv]\n",
    "valid_files = [read_csv(file) for file in valid_csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_path = 'img/02_glas_patch'\n",
    "imgs_path = 'img/02_glas_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glas_paths = [str(path) for path in Path(imgs_path).rglob('*.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches_files(folds, all_files):\n",
    "    out = []\n",
    "    for fold in folds:\n",
    "        matches = []\n",
    "        for name in fold:\n",
    "            for f in all_files:\n",
    "                if name in f:\n",
    "                    matches.append(f)\n",
    "        out.append(list(set(matches)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches = get_patches_files(train_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches = get_patches_files(test_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patches = get_patches_files(valid_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "for fold in train_patches:\n",
    "    print(len(fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_FINETUNE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histonet_glas'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IS_FINETUNE:\n",
    "    MODEL_NAME = 'histonet_X1.7_clrdecay_5'\n",
    "else:\n",
    "    MODEL_NAME = 'histonet_glas'\n",
    "    \n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NAME = '02_glas_full'\n",
    "INPUT_MODE = 'patch'                    # {'patch', 'wsi'}\n",
    "INPUT_SIZE = [224, 224]                 # [<int>, <int>] > 0\n",
    "HTT_MODE = 'glas'                       # {'both', 'morph', 'func', 'glas'}\n",
    "BATCH_SIZE = 1                          # int > 0\n",
    "GT_MODE = 'on'                          # {'on', 'off'}\n",
    "RUN_LEVEL = 3                           # {1: HTT confidence scores, 2: Grad-CAMs, 3: Segmentation masks}\n",
    "SAVE_TYPES = [1, 1, 1, 1]               # {HTT confidence scores, Grad-CAMs, Segmentation masks, Summary images}\n",
    "VERBOSITY = 'QUIET'                    # {'NORMAL', 'QUIET'}\n",
    "# Settings for image set\n",
    "IN_PX_RESOL = 0.620\n",
    "OUT_PX_RESOL = 0.25 * 1088 / 224    # 1.21428571429\n",
    "DOWNSAMPLE_FACTOR = OUT_PX_RESOL / IN_PX_RESOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsn = hsn_v1.HistoSegNetV1(params={'input_name': INPUT_NAME, 'input_size': INPUT_SIZE, 'input_mode': INPUT_MODE,\n",
    "                                       'down_fac': DOWNSAMPLE_FACTOR, 'batch_size': BATCH_SIZE, 'htt_mode': HTT_MODE,\n",
    "                                       'gt_mode': GT_MODE, 'run_level': RUN_LEVEL, 'save_types': SAVE_TYPES,\n",
    "                                       'verbosity': VERBOSITY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/victor/anaconda3/envs/hsn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/victor/anaconda3/envs/hsn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "hsn.load_histonet(params={'model_name': MODEL_NAME}, pretrained=IS_FINETUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 51)                13107     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 51)                0         \n",
      "=================================================================\n",
      "Total params: 1,753,203\n",
      "Trainable params: 1,750,899\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "histonet = hsn.hn\n",
    "histonet.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    \n",
    "    # Random crop and resize     \n",
    "    crop_size = [416, 416, 3]\n",
    "    resize_size = [224, 224, 3]\n",
    "    x = tf.image.random_crop(x, crop_size)\n",
    "    x = tf.image.resize(x, resize_size)\n",
    "    \n",
    "    # Color shifts\n",
    "    x = tf.image.random_hue(x, 0.5)\n",
    "    x = tf.image.random_saturation(x, 0.5, 1.5)\n",
    "    x = tf.image.random_brightness(x, 0.5)\n",
    "    x = tf.image.random_contrast(x, 0.5, 1.5)\n",
    "    \n",
    "    # Random rotation\n",
    "    x = tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    \n",
    "    # Normalize\n",
    "    x = histonet.normalize_image(x, is_glas=True)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folds):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    GO_INDEX = 48\n",
    "    NUM_CLASSES = 51\n",
    "    \n",
    "    for fold in folds:\n",
    "        imgs = np.zeros((len(fold), 522, 775, 3))\n",
    "        for i, f in enumerate(fold):\n",
    "            img = np.asarray(Image.open(f), dtype=\"int32\")\n",
    "            imgs[i] = np.resize(img, (522,775,3))\n",
    "        \n",
    "        X.append(imgs)\n",
    "        \n",
    "        # Create labels, only class is G.O\n",
    "        y = np.zeros((len(imgs), NUM_CLASSES))\n",
    "        y[:,GO_INDEX] = 1\n",
    "        Y.append(y)\n",
    "    \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds, Y_train_folds = load_images(train_patches)\n",
    "X_test_folds, Y_test_folds = load_images(test_patches)\n",
    "X_val_folds, Y_val_folds = load_images(val_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(X_folds, Y_folds):\n",
    "    \n",
    "    dataset_folds = []\n",
    "    \n",
    "    for X, Y in zip(X_folds, Y_folds):\n",
    "        print(X.shape, Y.shape)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "        dataset = dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_datasets(X_train_folds, Y_train_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = histonet.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_FINETUNE:\n",
    "    weights_path = 'data/histonet_glas_ft.h5'\n",
    "else:\n",
    "    weights_path = 'data/histonet_glas.h5'\n",
    "model_chkpt = keras.callbacks.ModelCheckpoint(filepath=weights_path, monitor='val_loss', verbose=1,\n",
    "                                             save_best_only=True, save_weights_only=True)\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "num_folds = X_train_folds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_folds):\n",
    "    X_train, y_train = X_train_folds[i], Y_train_folds[i]\n",
    "    X_test, y_test = X_test_folds[i], Y_test_folds[i]\n",
    "    X_val, y_val = X_val_folds[i], Y_val_folds[i]\n",
    "\n",
    "    train_gen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "    \n",
    "    train_generator = train_gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    \n",
    "    model.fit_generator(train_generator, \n",
    "                        epochs=num_epochs, \n",
    "                        verbose=1, \n",
    "                        shuffle=True, \n",
    "                        callbacks=[model_chkpt],\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        steps_per_epoch=X_train_folds[0].shape[0]/batch_size)\n",
    "    \n",
    "#     model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), \n",
    "#               batch_size=4, callbacks=[model_chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
