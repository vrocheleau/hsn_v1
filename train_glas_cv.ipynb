{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import hsn_v1\n",
    "from tensorflow import keras\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_path = 'folds/glas/split_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_files = [str(path) for path in Path(folds_path).rglob('*.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(pattern):\n",
    "    def filter_inst(file):\n",
    "        if pattern in file:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return filter_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and sort CV csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv = list(filter(make_filter('valid'), folds_files))\n",
    "valid_csv.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = list(filter(make_filter('test'), folds_files))\n",
    "test_csv.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = list(filter(make_filter('train'), folds_files))\n",
    "train_csv.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    cols = [0,1,2]\n",
    "    col_names = ['img', 'gt', 'class']    \n",
    "    df = pd.read_csv(file, header=None, usecols=cols, names=col_names)\n",
    "    files = df[col_names[0]].tolist()\n",
    "    names = [f.replace('.bmp', '.png') for f in files]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [read_csv(file) for file in train_csv]\n",
    "test_files = [read_csv(file) for file in test_csv]\n",
    "valid_files = [read_csv(file) for file in valid_csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = 'img/02_glas_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glas_paths = [str(path) for path in Path(imgs_path).rglob('*.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches_files(folds, all_files):\n",
    "    out = []\n",
    "    for fold in folds:\n",
    "        matches = []\n",
    "        for name in fold:\n",
    "            for f in all_files:\n",
    "                if name in f:\n",
    "                    matches.append(f)\n",
    "        out.append(list(set(matches)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches = get_patches_files(train_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches = get_patches_files(test_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patches = get_patches_files(valid_files, glas_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in train_patches:\n",
    "    print(len(fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_FINETUNE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_FINETUNE:\n",
    "    MODEL_NAME = 'histonet_X1.7_clrdecay_5'\n",
    "else:\n",
    "    MODEL_NAME = 'histonet_glas'\n",
    "    \n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NAME = '02_glas_full'\n",
    "INPUT_MODE = 'patch'                    # {'patch', 'wsi'}\n",
    "INPUT_SIZE = [224, 224]                 # [<int>, <int>] > 0\n",
    "HTT_MODE = 'glas'                       # {'both', 'morph', 'func', 'glas'}\n",
    "BATCH_SIZE = 1                          # int > 0\n",
    "GT_MODE = 'on'                          # {'on', 'off'}\n",
    "RUN_LEVEL = 3                           # {1: HTT confidence scores, 2: Grad-CAMs, 3: Segmentation masks}\n",
    "SAVE_TYPES = [1, 1, 1, 1]               # {HTT confidence scores, Grad-CAMs, Segmentation masks, Summary images}\n",
    "VERBOSITY = 'QUIET'                    # {'NORMAL', 'QUIET'}\n",
    "# Settings for image set\n",
    "IN_PX_RESOL = 0.620\n",
    "OUT_PX_RESOL = 0.25 * 1088 / 224    # 1.21428571429\n",
    "DOWNSAMPLE_FACTOR = OUT_PX_RESOL / IN_PX_RESOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsn = hsn_v1.HistoSegNetV1(params={'input_name': INPUT_NAME, 'input_size': INPUT_SIZE, 'input_mode': INPUT_MODE,\n",
    "                                       'down_fac': DOWNSAMPLE_FACTOR, 'batch_size': BATCH_SIZE, 'htt_mode': HTT_MODE,\n",
    "                                       'gt_mode': GT_MODE, 'run_level': RUN_LEVEL, 'save_types': SAVE_TYPES,\n",
    "                                       'verbosity': VERBOSITY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsn.load_histonet(params={'model_name': MODEL_NAME}, pretrained=IS_FINETUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histonet = hsn.hn\n",
    "histonet.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    \n",
    "    # Random crop and resize     \n",
    "    crop_size = [416, 416, 3]\n",
    "    resize_size = [224, 224]\n",
    "    x = tf.image.random_crop(x, crop_size)\n",
    "    x = tf.image.resize(x, resize_size)\n",
    "    \n",
    "    # Color shifts\n",
    "    x = tf.image.random_hue(x, 0.5)\n",
    "    x = tf.image.random_saturation(x, 0.5, 1.5)\n",
    "    x = tf.image.random_brightness(x, 0.5)\n",
    "    x = tf.image.random_contrast(x, 0.5, 1.5)\n",
    "    \n",
    "    # Random rotation\n",
    "    x = tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    \n",
    "    # Normalize\n",
    "    x = histonet.normalize_image(x, is_glas=True)\n",
    "    train_mean = 193.09203\n",
    "    train_std = 56.450138\n",
    "    x = tf.clip_by_value(x, 0, 255)\n",
    "    x = (x - train_mean)/(train_std + 1e-7)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folds):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    GO_INDEX = 48\n",
    "    NUM_CLASSES = 51\n",
    "    \n",
    "    for fold in folds:\n",
    "        imgs = np.zeros((len(fold), 522, 775, 3))\n",
    "        for i, f in enumerate(fold):\n",
    "            img = np.asarray(Image.open(f), dtype=\"int32\")\n",
    "            imgs[i] = np.resize(img, (522,775,3))\n",
    "        \n",
    "        X.append(imgs)\n",
    "        \n",
    "        # Create labels, only class is G.O\n",
    "        y = np.zeros((len(imgs), NUM_CLASSES))\n",
    "        y[:,GO_INDEX] = 1\n",
    "        Y.append(y)\n",
    "    \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds, Y_train_folds = load_images(train_patches)\n",
    "X_test_folds, Y_test_folds = load_images(test_patches)\n",
    "X_val_folds, Y_val_folds = load_images(val_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_folds[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(X_folds, Y_folds):\n",
    "    \n",
    "    dataset_folds = []\n",
    "    \n",
    "    for X, Y in zip(X_folds, Y_folds):\n",
    "        print(X.shape, Y.shape)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "        dataset = dataset.map(preprocess)\n",
    "        \n",
    "        dataset_folds.append(dataset)\n",
    "    \n",
    "    return dataset_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = load_datasets(X_train_folds, Y_train_folds)\n",
    "test_datasets = load_datasets(X_test_folds, Y_test_folds)\n",
    "val_datasets = load_datasets(X_val_folds, Y_val_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = histonet.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_FINETUNE:\n",
    "    weights_path = 'data/histonet_glas_ft.h5'\n",
    "else:\n",
    "    weights_path = 'data/histonet_glas.h5'\n",
    "model_chkpt = keras.callbacks.ModelCheckpoint(filepath=weights_path, monitor='val_loss', verbose=1,\n",
    "                                             save_best_only=True, save_weights_only=True)\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 1\n",
    "num_folds = X_train_folds.shape[0]\n",
    "num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_per_epoch = [(len(fold))//batch_size for fold in train_patches]\n",
    "val_steps_per_epoch = [(len(fold))//batch_size for fold in val_patches]\n",
    "\n",
    "train_steps_per_epoch, val_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_folds):\n",
    "    \n",
    "    print('***** FOLD {} *****'.format(i))\n",
    "    \n",
    "    train_dataset = train_datasets[i].batch(batch_size)\n",
    "    test_dataset = test_datasets[i].batch(batch_size)\n",
    "    val_dataset = val_datasets[i].batch(batch_size)\n",
    "    \n",
    "    model.fit(train_dataset, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=val_dataset, \n",
    "              steps_per_epoch=train_steps_per_epoch[i], \n",
    "              validation_steps=val_steps_per_epoch[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
